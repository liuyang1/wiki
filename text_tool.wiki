=文本工具=
mtime:2012-09-23 23:06:31
== head ==
- -c        as char (default line)
- -n        line

when using *-* or negtive number, that means display all but exclude last K
chars or lines

== tail ==
显示文件的开始或者结束部分.

- -f        follow
- -c        --bytes
- -n        LineNo, outoput last LineNo line
            +LineNo, start from LineNo

`tail -f filename`

跟踪显示文件内容,特别用于 *日志更新显示* .

`tail -c+10 filename`

output all binary content but first 10 bytes

`tail -n+10 filename`

output all content from 10 line

== tr ==
truncate char in IO

== multitail ==
多日志文件跟踪工具

multitail *.log

默认为水平分割.

multitail *.log -s 2

竖直分割,并且分割为2列

==sed&awk==
- [[awk]]
- [[sed]]

== cut ==

cut -s -d '.' -f2

从标准输入,以点进行分割,获取第2部分.

cut -s -d '.' -f1-2

获取第1~2部分

*可以用于提取文件名的前缀*

- -f, --fileds=LIST

=== LIST syntax ===
* N         N'th bytes, char, or field, counted from 1
* N-        from N'th bytes, char, fileds, to end of line
* N-M
* -M

== paste ==
combine every two line, convient for [[pacman]] or yaourt.

`paste -d " "  - - < filename`

== join ==

== 字符编码转换 ==
=== convmv ===

文件名字符转换

`convmv -f gbk -t utf8 --notest --nosmart`

=== iconv ===

文件内容转换

`iconv -f gbk -t utf8 address.csv > address.utf8.csv`

=== uconv ===
unicode convert

=== luit ===
实时将其他字符编码结果的程序,进行转码.

例如使用luit+telnet访问bbs.

luit -encoding gbk telnet bbs.ustc.edu.cn

== echo ==
* -n,不加回车符号
* -e,支持内嵌\xXX16进制任意字符
    expand "\t" to tab

== 正则匹配 ==
=== grep ===
- -E                extend RE mode(same with egrep)
- --color=[WHEN]    when=always/never/auto
- -l, --files-with-mathces
- -L, --files-without-mathces   file files which cannot match that strings
- -R, -r, --recursive           recursive under each directory
- -i                ignore case
- -v                reverse
- -A/-B             after/before context with [NUM] of lines
- -C                print [NUM] lines of output context
- -q                quiet, output nothing to stdout, but exit with zero status
   if found match
- -m [NUM]          Stop reading a file after [NUM] matching lines.

grep -E "WORD|"     match every line, and colorize WORD
grep -e '&' -e "WORD" match every line, and colorize WORD

=== more grep ===
==== egrep ====
==== pgrep / pkill ====
- -f                full command line, not only process name
- -u                user
- -v                reverse(negates) the matching

only pgrep (NOT for pkill)
- -d                delimiter(default to newline)
- -l                also list process name, (default only process ID)

==== pstree ====
show process status as tree
- -p                show pid

==== ack ====

# -u 无类型,强行匹配(和grep的默认状态是一样的)
# --nocolor   去除颜色输出(当需要后续处理的时候,可以采用)
# -n 不递归到子目录去，只在当前目录匹配

==== ag ====
# multi-pattern
ag "(header0|header1)tail"

- -H, no heading
== issue ==
match ctags, as --all-text / -t will override --ignore
== tee ==
如何将标准输出同时重定向到文件,并且同时显示到屏幕上

如下:

`cat 2>&1 | tee -a [logfile]`

`cat 2 > logfile | cat - logfile`

这是利用了cat可以显示到多个文件

以及tee可以输出到文件以及标准输出的功能.

其中tee 的-a参数,表示的是追加,这样不会覆盖文件之前的内容

== colorful output ==
- on            always ouput ANSI style colorful text
- off           never output color
- auto          output colorful text when detect tty (and PIPE isn't tty)

so how to display colorful content after filter by grep or more/less?

# grep always output colorful
# less output color, not filter

`cat testfile | egrep '3022|' --color=always | less -R`

== more / less ==
pager

- -R            raw output (not filter ANSI-char)
- +F
similar with `tail -f`, but can interrupt trace (by `<Ctrl-C>`) or resume by
`F`.

== most ==

== diff ==

== patch ==

`patch -p[NUM] < PATCHFILE`

NUM is level
== diffstat ==

== comm ==
compare sorted file

== pv ==
progress of pipe

`dd if=/dev/urandom | pv | dd of=/dev/null`

== on file type ==
- HTML to text
    lynx -dump -stdin
- makrdown, html convertor
    pandoc
=== xml ===
==== xmlstarlet ====
its command name is `xml`

xml format 1.xml    pretty-print xml
==== xmllint ====
- valid         validate the doc with xsd (std well-formed check)
- xinclude      do Xinclude processing
- format        pretty-print

==== xpath/xpointer ====



- JSON: jq
- YAML: shyaml
- csv: csvkit
- Amazon S3: s3cmd, s4cmd, aws, saws
